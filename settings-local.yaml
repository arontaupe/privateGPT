server:
  env_name: ${APP_ENV:local}

llm:
  mode: local
  # Should be matching the selected model
  max_new_tokens: 128
  context_window: 3800
  tokenizer: mistralai/Mistral-7B-Instruct-v0.2
  prompt_style: "mistral"
  llm_hf_repo_id: TheBloke/Mistral-7B-Instruct-v0.2-GGUF
  llm_hf_model_file: mistral-7b-instruct-v0.2.Q3_K_M.gguf
  embedding_hf_model_name: BAAI/bge-small-en-v1.5
  mode: local


local:
  prompt_style: "mistral"
  llm_hf_repo_id: TheBloke/Mistral-7B-Instruct-v0.2-GGUF
  llm_hf_model_file: mistral-7b-instruct-v0.2.Q3_K_M.gguf
  embedding_hf_model_name: BAAI/bge-small-en-v1.5
